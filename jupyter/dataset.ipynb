{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "image_path = '/home/data/BraTs_Seg_Study/data/testImage'\n",
    "mask_path = '/home/data/BraTs_Seg_Study/data/testMask'\n",
    "\n",
    "image_save_dir = 'testImage/'\n",
    "mask_save_dir = 'testMask/'\n",
    "imagenames = os.listdir(image_path)\n",
    "masknames = os.listdir(mask_path)\n",
    "\n",
    "listfile = '../BrainSeg_test.txt'\n",
    "fw = open(listfile,'w+')\n",
    "for imagename,maskname in zip(imagenames,masknames):\n",
    "    image_save_path = os.path.join(image_save_dir,imagename)\n",
    "    mask_save_path = os.path.join(mask_save_dir,maskname)\n",
    "    fw.write(image_save_path+' '+mask_save_path +'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class BrainSegDataset(Dataset):\n",
    "    def __init__(self,root,listfile,model='train',augment=False):\n",
    "        self.root = root \n",
    "        self.filenames = []\n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "        fr = open(listfile, 'r')\n",
    "        lines = fr.readlines()\n",
    "        for line in lines:\n",
    "            linesplit = line.split(' ')\n",
    "            image = os.path.join(root,linesplit[0])\n",
    "            mask = os.path.join(root,linesplit[0])\n",
    "            self.images.append(image.strip())\n",
    "            self.masks.append(mask.strip())\n",
    "            self.filenames.append(linesplit[0])\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        image = np.load(image)\n",
    "        mask = np.load(mask)\n",
    "        return image,mask \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brainseg = BrainSegDataset('/home/data/BraTs_Seg_Study/data','../BrainSeg_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "image shape:  torch.Size([1, 160, 160, 4])\nmask shape:  torch.Size([1, 160, 160, 4])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f3788c7c99b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image shape: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask shape: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainloader = DataLoader(brainseg)\n",
    "for image,mask in trainloader:\n",
    "    print('image shape: ',image.shape)\n",
    "    print('mask shape: ',mask.shape)\n",
    "    assert 1>3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}